Hướng dẫn Ôn tập AWS Certified AI Practitioner - Domain 1: Fundamentals of AI and ML
Tài liệu này cung cấp kiến thức tổng quan, chi tiết về các khái niệm cơ bản của Trí tuệ nhân tạo (AI) và Học máy (ML), bám sát các mục tiêu của Domain 1 trong kỳ thi AWS Certified AI Practitioner.
Task Statement 1.1: Giải thích các khái niệm và thuật ngữ AI cơ bản
Phần này tập trung vào việc định nghĩa và phân biệt các thuật ngữ nền tảng trong lĩnh vực AI và ML.
Mục tiêu 1.1.1: Định nghĩa các thuật ngữ AI cơ bản
Trí tuệ nhân tạo (Artificial Intelligence - AI): Là một lĩnh vực rộng lớn của khoa học máy tính, tập trung vào việc tạo ra các hệ thống máy tính có khả năng thực hiện các nhiệm vụ thường đòi hỏi trí thông minh của con người. Ví dụ: nhận dạng giọng nói, ra quyết định, dịch thuật. AI là khái niệm bao trùm tất cả.
Học máy (Machine Learning - ML): Là một nhánh của AI, cung cấp cho máy tính khả năng "học" từ dữ liệu mà không cần lập trình tường minh. Thay vì viết các quy tắc cụ thể, chúng ta "huấn luyện" một thuật toán bằng cách cho nó xem rất nhiều ví dụ.
Học sâu (Deep Learning): Là một lĩnh vực con của ML, sử dụng các mạng nơ-ron nhân tạo (neural networks) với nhiều lớp (do đó có từ "sâu") để học các mẫu phức tạp từ lượng lớn dữ liệu. Deep Learning là động lực đằng sau những đột phá gần đây trong nhận dạng hình ảnh và xử lý ngôn ngữ.
Mạng nơ-ron (Neural Networks): Lấy cảm hứng từ bộ não con người, đây là một hệ thống các "nơ-ron" nhân tạo được kết nối với nhau. Mỗi kết nối có thể truyền tín hiệu từ nơ-ron này sang nơ-ron khác, và mạng lưới này học bằng cách điều chỉnh sức mạnh (trọng số) của các kết nối đó.
Thị giác máy tính (Computer Vision): Một lĩnh vực của AI giúp máy tính "nhìn" và hiểu thông tin hình ảnh và video. Ví dụ: Mở khóa điện thoại bằng khuôn mặt, xe tự lái nhận diện biển báo giao thông.
Xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP): Cho phép máy tính hiểu, diễn giải và tạo ra ngôn ngữ của con người. Ví dụ: Trợ lý ảo như Alexa, Google Translate, chatbot dịch vụ khách hàng.
Mô hình (Model): Là kết quả đầu ra của quá trình huấn luyện ML. Về cơ bản, nó là một tập hợp các quy tắc và mẫu được thuật toán học từ dữ liệu. Bạn cung cấp dữ liệu đầu vào cho mô hình, và nó sẽ đưa ra một dự đoán hoặc quyết định.
Thuật toán (Algorithm): Là quy trình hoặc công thức mà một hệ thống ML sử dụng để học từ dữ liệu và tạo ra một mô hình. Ví dụ: thuật toán hồi quy tuyến tính (Linear Regression), cây quyết định (Decision Tree).
Huấn luyện (Training) và Suy luận (Inferencing):
Training: Là quá trình "dạy" cho mô hình bằng cách cung cấp dữ liệu đã được gán nhãn. Trong quá trình này, thuật toán điều chỉnh các tham số nội bộ của nó để tìm ra các mẫu.
Inferencing: Là quá trình sử dụng mô hình đã được huấn luyện để đưa ra dự đoán trên dữ liệu mới, chưa từng thấy trước đây. Đây là giai đoạn triển khai mô hình vào thực tế.
Thiên vị (Bias): Là xu hướng của mô hình đưa ra các dự đoán thiếu chính xác một cách có hệ thống cho một nhóm cụ thể. Điều này thường xảy ra khi dữ liệu huấn luyện không đại diện đầy đủ cho thực tế hoặc phản ánh những định kiến sẵn có của con người.
Ví dụ: Một mô hình tuyển dụng được huấn luyện chủ yếu trên hồ sơ của nam giới có thể có xu hướng đánh giá thấp các ứng viên nữ.
Công bằng (Fairness): Là nỗ lực để đảm bảo rằng các dự đoán của mô hình không bị ảnh hưởng tiêu cực bởi các đặc điểm nhạy cảm như giới tính, chủng tộc, hoặc tuổi tác. Đây là một mục tiêu quan trọng để xây dựng các hệ thống AI có trách nhiệm.
Độ phù hợp (Fit): Mô tả mức độ mô hình khớp với dữ liệu.
Underfitting (Dưới khớp): Mô hình quá đơn giản, không nắm bắt được các mẫu cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả dữ liệu huấn luyện và dữ liệu mới.
Overfitting (Quá khớp): Mô hình quá phức tạp, "học thuộc lòng" dữ liệu huấn luyện, bao gồm cả nhiễu. Nó hoạt động rất tốt trên dữ liệu đã thấy nhưng lại dự đoán rất tệ trên dữ liệu mới.
Good Fit (Khớp tốt): Mô hình đủ phức tạp để nắm bắt các mẫu cơ bản nhưng không quá phức tạp đến mức học cả nhiễu. Đây là điểm cân bằng lý tưởng.
Mô hình ngôn ngữ lớn (Large Language Model - LLM): Là một loại mô hình Deep Learning được huấn luyện trên một kho dữ liệu văn bản khổng lồ để hiểu và tạo ra ngôn ngữ tự nhiên. Ví dụ: GPT-4, LLaMA.
Mục tiêu 1.1.2: Mô tả sự tương đồng và khác biệt giữa AI, ML, và Deep Learning
Cách dễ nhất để hình dung mối quan hệ này là các vòng tròn đồng tâm: AI là vòng tròn lớn nhất, bên trong nó là ML, và bên trong ML là Deep Learning.
AI (Trí tuệ nhân tạo): Khái niệm tổng quát về việc máy móc bắt chước trí thông minh của con người.
ML (Học máy): Một cách tiếp cận cụ thể để đạt được AI, trong đó máy móc học từ dữ liệu.
DL (Học sâu): Một kỹ thuật chuyên sâu trong ML, sử dụng các mạng nơ-ron phức tạp để học các mẫu tinh vi.

Đặc điểm
Trí tuệ nhân tạo (AI)
Học máy (ML)
Học sâu (DL)
Phạm vi
Rộng nhất, bao gồm tất cả
Nhánh của AI
Lĩnh vực con của ML
Mục tiêu
Mô phỏng trí thông minh của con người
Học từ dữ liệu để dự đoán
Tự động học các đặc trưng phức tạp
Phương pháp
Logic, quy tắc, học máy,...
Thuật toán thống kê
Mạng nơ-ron sâu (nhiều lớp)
Yêu cầu dữ liệu
Có thể không cần dữ liệu (hệ chuyên gia)
Cần dữ liệu
Cần lượng dữ liệu rất lớn
Ví dụ
Robot chơi cờ, hệ chuyên gia
Dự đoán giá nhà, phân loại email
Xe tự lái, nhận dạng khuôn mặt

Mục tiêu 1.1.3: Mô tả các loại suy luận (Inferencing)
Suy luận theo lô (Batch Inferencing): Xử lý một lượng lớn dữ liệu đầu vào cùng một lúc và tạo ra các dự đoán. Quá trình này không diễn ra theo thời gian thực và thường được lên lịch để chạy định kỳ (ví dụ: hàng đêm).
Ví dụ: Một ngân hàng xử lý tất cả các giao dịch trong ngày vào cuối ngày để phát hiện gian lận.
Suy luận thời gian thực (Real-time Inferencing): Tạo ra dự đoán gần như ngay lập tức khi nhận được dữ liệu đầu vào. Yêu cầu độ trễ thấp.
Ví dụ: Một ứng dụng dịch thuật dịch lời nói của bạn ngay khi bạn đang nói, hoặc một hệ thống đề xuất sản phẩm cập nhật ngay khi bạn duyệt web.
Mục tiêu 1.1.4: Mô tả các loại dữ liệu trong mô hình AI
Dữ liệu có nhãn (Labeled Data) và không có nhãn (Unlabeled Data):
Labeled Data: Dữ liệu đã được gán một "câu trả lời" hoặc "nhãn" đúng. Cần thiết cho học có giám sát. Ví dụ: một bộ sưu tập ảnh động vật, trong đó mỗi ảnh được gắn nhãn "chó" hoặc "mèo".
Unlabeled Data: Dữ liệu thô, không có câu trả lời định trước. Được sử dụng trong học không giám sát. Ví dụ: một bộ sưu tập ảnh động vật chưa được phân loại.
Dữ liệu dạng bảng (Tabular Data): Dữ liệu được tổ chức dưới dạng hàng và cột, giống như trong bảng tính hoặc cơ sở dữ liệu. Đây là loại dữ liệu phổ biến nhất.
Dữ liệu chuỗi thời gian (Time-series Data): Một chuỗi các điểm dữ liệu được sắp xếp theo thứ tự thời gian. Ví dụ: giá cổ phiếu hàng ngày, dữ liệu thời tiết hàng giờ.
Dữ liệu hình ảnh (Image Data): Bao gồm ảnh, video.
Dữ liệu văn bản (Text Data): Bao gồm email, tài liệu, tweet, v.v.
Dữ liệu có cấu trúc (Structured Data) và phi cấu trúc (Unstructured Data):
Structured Data: Dữ liệu có một mô hình hoặc cấu trúc được xác định trước, dễ dàng tổ chức trong bảng. Ví dụ: dữ liệu dạng bảng.
Unstructured Data: Dữ liệu không có cấu trúc tổ chức rõ ràng. Ví dụ: văn bản, hình ảnh, âm thanh. Hơn 80% dữ liệu trên thế giới là phi cấu trúc.

Mục tiêu 1.1.5: Mô tả học có giám sát, không giám sát và học tăng cường
Loại học
Mô tả
Loại dữ liệu
Mục tiêu
Ví dụ
Học có giám sát (Supervised Learning)
Học từ dữ liệu đã được gán nhãn để dự đoán kết quả cho dữ liệu mới. Giống như học với một người thầy.
Có nhãn
Dự đoán nhãn hoặc một giá trị liên tục.
Phân loại email là spam hay không. Dự đoán giá nhà.
Học không giám sát (Unsupervised Learning)
Học từ dữ liệu không có nhãn để khám phá các mẫu hoặc cấu trúc tiềm ẩn.
Không có nhãn
Tìm các cụm (clusters) hoặc các mối liên hệ.
Phân nhóm khách hàng dựa trên hành vi mua sắm.
Học tăng cường (Reinforcement Learning)
Một "tác nhân" học cách hành động trong một "môi trường" để tối đa hóa phần thưởng. Học thông qua thử và sai.
Không cần dữ liệu ban đầu
Học một chuỗi các quyết định tối ưu (chính sách).
Huấn luyện một AI chơi game. Robot tự học cách đi.

Task Statement 1.2: Xác định các trường hợp sử dụng AI trong thực tế
Phần này khám phá cách áp dụng AI/ML để giải quyết các vấn đề trong thế giới thực và khi nào nên hoặc không nên sử dụng chúng.
Mục tiêu 1.2.1: Nhận biết các ứng dụng mà AI/ML có thể mang lại giá trị
Hỗ trợ ra quyết định của con người: AI có thể phân tích lượng lớn dữ liệu để cung cấp thông tin chi tiết, giúp con người đưa ra quyết định tốt hơn và nhanh hơn.
Ví dụ: Một hệ thống AI phân tích hình ảnh y tế để đánh dấu các khu vực đáng ngờ cho bác sĩ X-quang xem xét.
Khả năng mở rộng giải pháp (Solution Scalability): AI có thể tự động hóa các tác vụ lặp đi lặp lại trên quy mô lớn mà con người không thể thực hiện hiệu quả.
Ví dụ: Một công ty thương mại điện tử sử dụng chatbot để xử lý hàng nghìn yêu cầu của khách hàng cùng một lúc.
Tự động hóa (Automation): Tự động hóa các quy trình thủ công để giảm chi phí, tăng hiệu quả và giảm lỗi do con người.
Ví dụ: Tự động phân loại và định tuyến các email hỗ trợ đến đúng bộ phận.
Mục tiêu 1.2.2: Xác định khi nào giải pháp AI/ML không phù hợp
Phân tích Chi phí-Lợi ích (Cost-benefit analyses): Việc xây dựng, triển khai và bảo trì một hệ thống ML có thể tốn kém. Nếu một giải pháp đơn giản hơn (như một bộ quy tắc) có thể giải quyết vấn đề với chi phí thấp hơn, thì AI/ML có thể không phải là lựa chọn tốt nhất.
Khi cần một kết quả cụ thể, không phải là dự đoán: Các mô hình ML đưa ra dự đoán dựa trên xác suất, chúng không bao giờ chắc chắn 100%. Nếu một quy trình kinh doanh yêu cầu một kết quả chính xác, tất định, thì không nên dùng ML.
Ví dụ: Một hệ thống tính lương phải tính toán chính xác số tiền phải trả, không thể "dự đoán" mức lương.
Khi không có đủ dữ liệu chất lượng: Các mô hình ML cần lượng lớn dữ liệu chất lượng cao để học. Nếu không có dữ liệu, hoặc dữ liệu bị nhiễu và thiên vị, mô hình sẽ hoạt động kém.
Mục tiêu 1.2.3: Lựa chọn kỹ thuật ML phù hợp cho các trường hợp sử dụng cụ thể
Đây là một trong những kỹ năng quan trọng nhất. Dưới đây là cách ánh xạ các loại vấn đề với các kỹ thuật ML:
Câu hỏi kinh doanh
Loại vấn đề ML
Kỹ thuật ML
Ví dụ
"Đây là A hay B (hay C)?"
Phân loại (Classification)
Logistic Regression, Decision Tree, SVM
Giao dịch này có gian lận không? Email này có phải là spam không?
"Bao nhiêu/Bao nhiêu tiền?"
Hồi quy (Regression)
Linear Regression, Gradient Boosting
Giá của ngôi nhà này sẽ là bao nhiêu? Chúng ta sẽ bán được bao nhiêu sản phẩm vào tháng tới?
"Làm thế nào để tổ chức/nhóm những thứ này?"
Phân cụm (Clustering)
K-Means, DBSCAN
Phân nhóm khách hàng dựa trên hành vi của họ.
"Điều gì sẽ xảy ra tiếp theo?"
Dự báo (Forecasting)
ARIMA, LSTM
Dự báo nhu cầu sản phẩm trong quý tới.

Mục tiêu 1.2.4: Xác định các ví dụ về ứng dụng AI trong thế giới thực
Thị giác máy tính (Computer Vision): Xe tự lái, nhận dạng khuôn mặt trên mạng xã hội, kiểm soát chất lượng sản phẩm trên dây chuyền sản xuất.
Xử lý ngôn ngữ tự nhiên (NLP): Phân tích tình cảm (sentiment analysis) của các bài đánh giá sản phẩm, dịch máy, tóm tắt văn bản.
Nhận dạng giọng nói (Speech Recognition): Chuyển đổi lời nói thành văn bản trong các trợ lý ảo (Siri, Alexa), tạo phụ đề tự động cho video.
Hệ thống đề xuất (Recommendation Systems): Netflix đề xuất phim, Amazon đề xuất sản phẩm, Spotify đề xuất bài hát.
Phát hiện gian lận (Fraud Detection): Các công ty thẻ tín dụng sử dụng ML để xác định các giao dịch đáng ngờ trong thời gian thực.
Dự báo (Forecasting): Các nhà bán lẻ dự báo nhu cầu hàng tồn kho, các công ty năng lượng dự báo mức tiêu thụ điện.
Mục tiêu 1.2.5: Giải thích khả năng của các dịch vụ AI/ML được quản lý của AWS
AWS cung cấp các dịch vụ AI ở nhiều cấp độ khác nhau, từ các API dễ sử dụng đến các nền tảng xây dựng mô hình phức tạp.
Amazon SageMaker: Một nền tảng toàn diện để xây dựng, huấn luyện và triển khai các mô hình ML trên quy mô lớn. Đây là công cụ dành cho các nhà khoa học dữ liệu và nhà phát triển ML.
Amazon Transcribe: Dịch vụ nhận dạng giọng nói tự động (ASR) giúp chuyển đổi âm thanh thành văn bản.
Amazon Translate: Dịch vụ dịch máy nơ-ron để dịch văn bản giữa các ngôn ngữ.
Amazon Comprehend: Dịch vụ NLP giúp khám phá thông tin chi tiết và mối quan hệ trong văn bản, chẳng hạn như xác định thực thể, phân tích tình cảm, và trích xuất cụm từ chính.
Amazon Lex: Dịch vụ để xây dựng các giao diện trò chuyện (chatbot) bằng giọng nói và văn bản. Đây là công nghệ đằng sau Alexa.
Amazon Polly: Dịch vụ chuyển văn bản thành giọng nói (TTS) tự nhiên.
Task Statement 1.3: Mô tả vòng đời phát triển ML
Phần này mô tả quy trình từng bước để đưa một mô hình ML từ ý tưởng đến sản xuất và vận hành.
Mục tiêu 1.3.1: Mô tả các thành phần của một đường ống ML (ML pipeline)
Vòng đời phát triển ML là một quy trình lặp đi lặp lại, không phải là một đường thẳng.
Thu thập dữ liệu (Data Collection): Tập hợp dữ liệu thô từ nhiều nguồn khác nhau (cơ sở dữ liệu, API, tệp tin).
Phân tích dữ liệu khám phá (Exploratory Data Analysis - EDA): Tìm hiểu, trực quan hóa và tóm tắt dữ liệu để hiểu các đặc điểm, tìm ra các mẫu và xác định các vấn đề về chất lượng.
Tiền xử lý dữ liệu (Data Pre-processing): Làm sạch và chuyển đổi dữ liệu thô thành một định dạng phù hợp cho việc huấn luyện mô hình. Các bước bao gồm xử lý các giá trị bị thiếu, chuẩn hóa dữ liệu, v.v.
Kỹ thuật đặc trưng (Feature Engineering): Tạo ra các đặc trưng (biến đầu vào) mới từ dữ liệu hiện có để cải thiện hiệu suất của mô hình. Đây thường là bước tốn nhiều thời gian và sáng tạo nhất.
Huấn luyện mô hình (Model Training): Chạy thuật toán ML trên dữ liệu đã được xử lý để tạo ra một mô hình.
Tinh chỉnh siêu tham số (Hyperparameter Tuning): Tìm kiếm bộ siêu tham số (các cài đặt của thuật toán, không được học từ dữ liệu) tốt nhất để tối ưu hóa hiệu suất của mô hình.
Đánh giá (Evaluation): Đánh giá hiệu suất của mô hình trên một tập dữ liệu riêng biệt (tập kiểm tra) để xem nó hoạt động tốt như thế nào trên dữ liệu mới.
Triển khai (Deployment): Tích hợp mô hình đã được huấn luyện vào một ứng dụng sản xuất để nó có thể bắt đầu đưa ra dự đoán.
Giám sát (Monitoring): Theo dõi liên tục hiệu suất của mô hình trong môi trường sản xuất để phát hiện sự suy giảm hiệu suất (model drift) và quyết định khi nào cần huấn luyện lại.
Mục tiêu 1.3.2: Hiểu các nguồn của mô hình ML
Mô hình được đào tạo trước mã nguồn mở (Open source pre-trained models): Các mô hình đã được huấn luyện trên các bộ dữ liệu lớn (ví dụ: hình ảnh từ ImageNet, văn bản từ Wikipedia) và được cung cấp miễn phí. Chúng có thể được sử dụng trực tiếp hoặc tinh chỉnh (fine-tuning) trên bộ dữ liệu nhỏ hơn của riêng bạn.
Lợi ích: Tiết kiệm thời gian và chi phí tính toán.
Ví dụ: BERT cho NLP, ResNet cho thị giác máy tính.
Huấn luyện mô hình tùy chỉnh (Training custom models): Xây dựng và huấn luyện một mô hình từ đầu bằng cách sử dụng dữ liệu và thuật toán của riêng bạn.
Lợi ích: Mô hình được tối ưu hóa cho trường hợp sử dụng cụ thể của bạn.
Yêu cầu: Cần nhiều dữ liệu, chuyên môn và tài nguyên tính toán.
Mục tiêu 1.3.3: Mô tả các phương pháp sử dụng mô hình trong sản xuất
Dịch vụ API được quản lý (Managed API service): Triển khai mô hình của bạn như một điểm cuối (endpoint) API được quản lý bởi một nhà cung cấp dịch vụ đám mây như AWS (ví dụ: Amazon SageMaker Endpoints).
Lợi ích: Dễ dàng, tự động mở rộng, không cần quản lý cơ sở hạ tầng.
API tự lưu trữ (Self-hosted API): Tự bạn triển khai mô hình trên máy chủ của riêng mình (tại chỗ hoặc trên máy ảo đám mây).
Lợi ích: Toàn quyền kiểm soát môi trường, có thể tiết kiệm chi phí hơn trong một số trường hợp.
Nhược điểm: Yêu cầu nhiều nỗ lực quản lý và bảo trì.
Mục tiêu 1.3.4: Xác định các dịch vụ và tính năng AWS liên quan cho từng giai đoạn của đường ống ML
Giai đoạn đường ống ML
Dịch vụ/Tính năng AWS liên quan
Thu thập & Lưu trữ dữ liệu
Amazon S3, Amazon Redshift, AWS Glue
EDA & Tiền xử lý dữ liệu
Amazon SageMaker Data Wrangler, Amazon EMR
Kỹ thuật đặc trưng
Amazon SageMaker Feature Store
Huấn luyện & Tinh chỉnh
Amazon SageMaker Training Jobs
Đánh giá & So sánh
Amazon SageMaker Experiments
Triển khai
Amazon SageMaker Endpoints
Giám sát
Amazon SageMaker Model Monitor
Điều phối toàn bộ quy trình
Amazon SageMaker Pipelines

Mục tiêu 1.3.5: Hiểu các khái niệm cơ bản của vận hành ML (MLOps)
MLOps là tập hợp các thực tiễn nhằm mục đích triển khai và duy trì các mô hình ML trong sản xuất một cách đáng tin cậy và hiệu quả. Nó kết hợp ML, DevOps và Kỹ thuật dữ liệu.
Thử nghiệm (Experimentation): Theo dõi và so sánh các lần chạy huấn luyện khác nhau để tìm ra mô hình tốt nhất.
Quy trình lặp lại (Repeatable processes): Tự động hóa toàn bộ đường ống ML để đảm bảo tính nhất quán và giảm thiểu lỗi thủ công.
Hệ thống có thể mở rộng (Scalable systems): Xây dựng các hệ thống có thể xử lý lượng dữ liệu và lưu lượng truy cập ngày càng tăng.
Quản lý nợ kỹ thuật (Managing technical debt): Nợ kỹ thuật trong ML có thể tích tụ do các lối tắt trong việc chuẩn bị dữ liệu, kỹ thuật đặc trưng hoặc giám sát mô hình. MLOps giúp quản lý điều này.
Đạt được sự sẵn sàng cho sản xuất (Achieving production readiness): Đảm bảo mô hình không chỉ chính xác mà còn mạnh mẽ, an toàn và có thể giám sát được trước khi triển khai.
Giám sát mô hình (Model monitoring): Theo dõi sự thay đổi trong dữ liệu đầu vào và hiệu suất của mô hình theo thời gian.
Huấn luyện lại mô hình (Model re-training): Tự động hóa quy trình huấn luyện lại mô hình trên dữ liệu mới để duy trì sự phù hợp của nó.
Mục tiêu 1.3.6: Hiểu các chỉ số hiệu suất mô hình và chỉ số kinh doanh
Việc đánh giá một mô hình cần cả hai loại chỉ số:
Chỉ số hiệu suất mô hình (Model Performance Metrics): Đo lường mức độ "chính xác" của các dự đoán của mô hình từ góc độ thống kê.
Độ chính xác (Accuracy): (Số dự đoán đúng) / (Tổng số dự đoán). Hữu ích khi các lớp cân bằng.
AUC (Area Under the ROC Curve): Một chỉ số tốt để đánh giá các mô hình phân loại nhị phân, đặc biệt là với dữ liệu không cân bằng. Giá trị càng gần 1, mô hình càng tốt.
F1 Score: Trung bình điều hòa của Precision và Recall. Hữu ích khi có sự đánh đổi giữa dương tính giả và âm tính giả.
Chỉ số kinh doanh (Business Metrics): Đo lường tác động của mô hình đối với các mục tiêu kinh doanh. Đây là thước đo thành công cuối cùng.
Chi phí cho mỗi người dùng (Cost per user): Chi phí vận hành mô hình là bao nhiêu?
Chi phí phát triển (Development costs): Chi phí để xây dựng mô hình là bao nhiêu?
Phản hồi của khách hàng (Customer feedback): Khách hàng có hài lòng với các đề xuất hoặc dự đoán của mô hình không?
Lợi tức đầu tư (Return on Investment - ROI): Mô hình có giúp tăng doanh thu hoặc giảm chi phí đủ để bù đắp cho việc đầu tư vào nó không?

Tài liệu học tập cho Domain 2: Nguyên lý cơ bản của AI tạo sinh
Lời Nói Đầu: Giới Thiệu về AI Tạo Sinh và Chứng Chỉ AWS AI Practitioner
Trí tuệ nhân tạo tạo sinh (Generative AI) đại diện cho một bước tiến mang tính cách mạng trong lĩnh vực trí tuệ nhân tạo (AI), mở ra khả năng tạo ra nội dung và ý tưởng mới một cách độc đáo và sáng tạo [1, 2]. Công nghệ này không chỉ giới hạn ở việc phân tích dữ liệu cũ mà còn sử dụng kiến thức đã học để giải quyết các vấn đề mới, từ đó nâng cao năng suất, thúc đẩy đổi mới sáng tạo và tạo ra giá trị kinh doanh đột phá [1, 3, 4]. Sự ra đời của các mô hình nền tảng (Foundation Models - FMs) và mô hình ngôn ngữ lớn (Large Language Models - LLMs) đã định hình kỷ nguyên mới, nơi các tổ chức có thể ứng dụng AI để tự động hóa, cá nhân hóa trải nghiệm khách hàng và tối ưu hóa quy trình hoạt động [5].
Tài liệu này được biên soạn nhằm cung cấp một cái nhìn toàn diện và có hệ thống về các nguyên lý cơ bản của AI tạo sinh, tập trung vào các chủ đề chính trong Domain 2 của kỳ thi chứng chỉ AWS Certified AI Practitioner. Báo cáo này sẽ đi sâu vào các khái niệm nền tảng, phân tích các trường hợp sử dụng, đánh giá cả khả năng và hạn chế của công nghệ, đồng thời mô tả chi tiết các dịch vụ và cơ sở hạ tầng của AWS hỗ trợ việc xây dựng các ứng dụng AI tạo sinh.

Phần 1: Các Khái Niệm Cơ Bản về AI Tạo Sinh (Task Statement 2.1)
1.1. Các Khái Niệm Nền Tảng của AI Tạo Sinh


Tokens, Tokenization, Chunking, Embeddings và Vectors

Để một mô hình AI có thể xử lý văn bản, nó không thể hiểu được toàn bộ câu hoặc đoạn văn một cách trực tiếp. Thay vào đó, văn bản cần được phân tách thành các đơn vị nhỏ hơn gọi là "tokens" [6, 7, 8]. Quá trình chuyển đổi này được gọi là "tokenization". Một token có thể là một từ, một phần của từ, hoặc thậm chí là một ký tự [7]. Các mô hình ngôn ngữ chỉ hoạt động trên những đơn vị nhỏ này để tạo ra các đầu ra mạch lạc và có ngữ cảnh [6].
Đối với các chuỗi đầu vào dài, chẳng hạn như toàn bộ tài liệu hoặc sách, mô hình phải đối mặt với một hạn chế cố hữu: "cửa sổ ngữ cảnh" (context window) có kích thước cố định [6]. Đây là giới hạn về lượng dữ liệu mà mô hình có thể ghi nhớ và xử lý cùng một lúc. Để giải quyết thách thức này, kỹ thuật "chunking" được áp dụng để chia các chuỗi dài thành các phần nhỏ hơn, dễ quản lý hơn [6]. Điều này đảm bảo rằng các đoạn văn bản có thể được xử lý trong giới hạn của cửa sổ ngữ cảnh, duy trì được ngữ cảnh và cấu trúc tổng thể [6].
Sau khi văn bản được chia thành các token, bước tiếp theo là chuyển đổi chúng thành định dạng mà mô hình có thể thực hiện các phép tính toán. Quá trình này được gọi là "embeddings," biến các token hoặc các loại dữ liệu khác như hình ảnh thành các "vectors" số học [6, 9]. Các vector này mã hóa ý nghĩa ngữ nghĩa của dữ liệu gốc, cho phép mô hình hiểu được các mối quan hệ phức tạp. Chẳng hạn, một mô hình có thể liên kết từ "elephant" với "acacia trees" vì trong dữ liệu huấn luyện, chúng thường xuất hiện cùng nhau [7]. Sự chuyển đổi này là cầu nối giữa ngôn ngữ tự nhiên và logic toán học của mô hình, là nền tảng kỹ thuật cho toàn bộ quá trình tạo sinh.

Prompt Engineering

"Prompt Engineering" là một kỹ năng thiết yếu trong việc tương tác với các mô hình AI tạo sinh [6, 10]. Đây là "nghệ thuật" và "khoa học" của việc tạo ra các câu lệnh (prompts) hiệu quả để điều khiển mô hình tạo ra kết quả mong muốn [6]. Thay vì lập trình bằng mã, người dùng "lập trình" bằng ngôn ngữ tự nhiên. Chất lượng của câu lệnh đầu vào là yếu tố trực tiếp quyết định chất lượng đầu ra [10].
Các kỹ thuật trong prompt engineering bao gồm:
Zero-shot learning: Hướng dẫn mô hình thực hiện một tác vụ mà không cung cấp bất kỳ ví dụ nào [6].
One-shot learning: Cung cấp một ví dụ duy nhất để mô hình học theo [6].
Few-shot learning: Cung cấp nhiều ví dụ để giúp mô hình hiểu và tái tạo tác vụ [6].
Sự phổ biến của kỹ thuật này cho thấy một sự thay đổi cơ bản trong cách con người tương tác với máy tính. Các dịch vụ như PartyRock được xây dựng để giúp người dùng phổ thông học kỹ năng này, cho thấy tầm quan trọng của nó trong việc hạ thấp rào cản gia nhập [11, 12].

Mô hình Transformer-based LLMs và Foundation Models (FM)

Kiến trúc mạng nơ-ron "Transformer" đã cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) [7, 9]. Ưu điểm cốt lõi của Transformer là khả năng xử lý song song toàn bộ chuỗi dữ liệu đầu vào thông qua một cơ chế gọi là "self-attention" [7]. Điều này giúp các mô hình có thể xử lý các chuỗi dữ liệu lớn một cách hiệu quả hơn nhiều so với các kiến trúc mạng nơ-ron tái phát (RNN) trước đây [6]. Khả năng xử lý song song này là nguyên nhân trực tiếp dẫn đến sự ra đời của các mô hình ngôn ngữ lớn (LLMs) khổng lồ với hàng trăm tỷ, thậm chí hàng nghìn tỷ tham số [7]. LLMs là một phân lớp của FM, được thiết kế đặc biệt cho các tác vụ dựa trên ngôn ngữ như tóm tắt, tạo văn bản, phân loại và trò chuyện [1, 13].
Mô hình nền tảng (Foundation Models - FMs) là các mô hình học máy được huấn luyện trên một lượng lớn dữ liệu không được dán nhãn [1, 13]. Chúng có khả năng thực hiện một loạt các tác vụ chung và có thể được tùy chỉnh để giải quyết các vấn đề cụ thể [14]. Một xu hướng quan trọng là các doanh nghiệp đang chuyển từ việc xây dựng các mô hình chuyên biệt từ đầu sang sử dụng các FM có sẵn và tinh chỉnh (fine-tune) chúng với dữ liệu riêng của mình [14, 15]. Cách tiếp cận này giúp tiết kiệm tài nguyên tính toán đáng kể và đẩy nhanh tốc độ triển khai ứng dụng [14].

Multi-modal Models và Diffusion Models

Mô hình "đa phương thức" (Multi-modal models) là các mô hình AI có khả năng xử lý và tạo ra nội dung từ nhiều loại dữ liệu khác nhau, chẳng hạn như văn bản, hình ảnh và video, cùng một lúc [6]. Khả năng này thể hiện sự tiến bộ lớn trong việc cho phép AI hiểu và tương tác với thế giới phức tạp. Cần lưu ý rằng khái niệm này không liên quan đến "vận tải đa phương thức" [16, 17], một thuật ngữ trong lĩnh vực logistics.
"Mô hình khuếch tán" (Diffusion models) là một loại mô hình học máy chuyên biệt để tạo ra dữ liệu, đặc biệt là hình ảnh, bằng cách học cách đảo ngược một quá trình thêm nhiễu (noise) vào dữ liệu ban đầu [6, 18]. Quá trình này bao gồm hai giai đoạn chính: "quá trình khuếch tán xuôi" (forward diffusion process), nơi nhiễu được thêm vào hình ảnh, và "quá trình khuếch tán ngược" (reverse diffusion process), nơi mô hình học cách loại bỏ nhiễu để tái tạo lại hình ảnh gốc [18]. Stable Diffusion [6, 19] là một ví dụ nổi bật, có khả năng tạo ra hình ảnh chân thực từ lời nhắc văn bản, được sử dụng rộng rãi trong các ngành công nghiệp sáng tạo để tạo, chỉnh sửa và phục hồi hình ảnh [6, 19].

1.2. Các Trường Hợp Sử Dụng Tiềm Năng của AI Tạo Sinh

AI tạo sinh đang chuyển mình từ một công cụ nghiên cứu sang một nền tảng hỗ trợ đa chức năng, có thể áp dụng trong nhiều lĩnh vực:
Tạo nội dung đa phương thức: Tạo hình ảnh, video và âm thanh từ các câu lệnh văn bản [1, 6]. Ứng dụng trong truyền thông, giải trí, và thiết kế [1, 20].
Tạo văn bản:
Chatbots và Trợ lý ảo: Cung cấp trải nghiệm dịch vụ khách hàng 24/7 và phản hồi nhanh chóng [1, 5].
Tóm tắt và phân tích tài liệu: Hỗ trợ các nhà quản lý tạo báo cáo và dự báo [1, 20].
Tạo nội dung và viết mã: Tạo email, blog, quảng cáo, hoặc đề xuất mã phần mềm mới [1, 21].
Ứng dụng trong các ngành cụ thể:
Tiếp thị và bán hàng: Tạo các chiến dịch tiếp thị hấp dẫn và nội dung email cá nhân hóa [1, 21].
Phát triển sản phẩm và thiết kế: Hỗ trợ các nhà thiết kế đồ họa tạo ra các nguyên mẫu và ý tưởng mới một cách nhanh chóng [1, 20].
Doanh nghiệp: Phân tích dữ liệu lớn để tìm ra các xu hướng tiềm ẩn và đưa ra các quyết định dựa trên dữ liệu [5].
1.3. Vòng Đời của Foundation Model

Vòng đời của một mô hình nền tảng (FM) phản ánh các giai đoạn của quy trình phát triển phần mềm (SDLC) và MLOps truyền thống [14, 22, 23], đảm bảo tính hệ thống và khả năng cải tiến liên tục [14]. Các giai đoạn chính bao gồm:
Phạm vi (Scoping): Giai đoạn đầu tiên và quan trọng nhất, nơi xác định rõ ràng vấn đề kinh doanh cần giải quyết, mục tiêu dự án, và các chỉ số đo lường thành công [24]. Việc xác định rõ phạm vi ngay từ đầu giúp tránh lãng phí tài nguyên và tập trung vào những mục tiêu có tác động lớn [14].
Lựa chọn mô hình (Model selection): Đánh giá và lựa chọn mô hình nền tảng phù hợp nhất với yêu cầu cụ thể của doanh nghiệp [14, 24]. Quá trình này cân nhắc giữa việc sử dụng mô hình được tiền huấn luyện có sẵn và tùy chỉnh chúng, hay huấn luyện một mô hình từ đầu cho các trường hợp chuyên biệt [14].
Tùy chỉnh mô hình (Model customization): Tinh chỉnh mô hình đã chọn bằng cách sử dụng dữ liệu độc quyền của doanh nghiệp [24].
Phát triển và tích hợp (Development and integration): Xây dựng ứng dụng xung quanh mô hình và tích hợp nó vào cơ sở hạ tầng hoặc quy trình làm việc hiện có [24].
Triển khai (Deployment): Đưa mô hình vào môi trường sản xuất. Giai đoạn này yêu cầu đảm bảo mô hình hoạt động hiệu quả, độ trễ thấp và có thể mở rộng [14].
Cải tiến liên tục (Continuous improvement): Sau khi triển khai, mô hình được theo dõi liên tục để đánh giá hiệu suất, thu thập phản hồi từ người dùng và dữ liệu mới, từ đó điều chỉnh và tối ưu hóa theo thời gian [14, 24].
Sự nhấn mạnh vào giai đoạn "scoping" và "cải tiến liên tục" cho thấy một dự án AI tạo sinh thành công không chỉ dựa vào công nghệ mà còn phụ thuộc vào việc xác định vấn đề kinh doanh đúng đắn và một quy trình quản lý vòng đời chặt chẽ [24].

Phần 2: Khả Năng và Hạn Chế trong Giải Quyết Bài Toán Kinh Doanh (Task Statement 2.2)
2.1. Ưu Điểm của AI Tạo Sinh

AI tạo sinh mang lại nhiều lợi ích vượt trội cho các doanh nghiệp, thể hiện qua các đặc điểm chính sau:
Tính thích ứng (Adaptability) và tính phản hồi (Responsiveness): Khả năng của AI tạo sinh trong việc hiểu và xử lý các lượng dữ liệu phức tạp nhanh hơn con người giúp tăng tốc độ ra quyết định [20]. Nhờ giao tiếp qua ngôn ngữ tự nhiên, một mô hình có thể được áp dụng cho nhiều nhiệm vụ khác nhau chỉ bằng cách thay đổi câu lệnh, không cần huấn luyện lại, từ đó thể hiện tính thích ứng cao [21].
Tính đơn giản (Simplicity): Giao diện tương tác dựa trên ngôn ngữ tự nhiên làm giảm đáng kể rào cản kỹ thuật. Người dùng không chuyên cũng có thể dễ dàng sử dụng AI tạo sinh để tạo nội dung, hỗ trợ công việc và khám phá dữ liệu, từ đó dân chủ hóa công nghệ AI [20].
Năng suất và hiệu quả: AI tạo sinh có thể tự động hóa các tác vụ lặp đi lặp lại và hỗ trợ các công việc sáng tạo [20, 25]. Ví dụ, nó có thể tạo ra các bản nháp báo cáo, tóm tắt tài liệu, hoặc đề xuất ý tưởng thiết kế, giúp nhân viên tập trung vào các nhiệm vụ chiến lược và đổi mới hơn [13, 20, 21].

2.2. Nhược Điểm và Thách Thức của AI Tạo Sinh

Mặc dù mang lại nhiều lợi ích, AI tạo sinh cũng có những hạn chế đáng kể mà các tổ chức cần cân nhắc:
Hallucinations (Ảo giác) và Inaccuracy (Tính không chính xác): Đây là hiện tượng mô hình AI tạo ra thông tin sai lệch, không chính xác hoặc không có cơ sở trong dữ liệu huấn luyện [10, 26]. Nguyên nhân xuất phát từ việc mô hình suy luận vượt quá giới hạn kiến thức, thiếu cơ chế kiểm chứng nguồn tin và có thể bị ảnh hưởng bởi dữ liệu đầu vào không đầy đủ [26]. Vấn đề này có thể gây mất lòng tin từ phía người dùng và doanh nghiệp [26].
Interpretability (Khả năng diễn giải): Các mô hình AI tạo sinh thường được coi là "hộp đen" [1, 27], nơi rất khó để hiểu cách chúng đưa ra một kết quả cụ thể. Khả năng diễn giải là yếu tố then chốt để xây dựng niềm tin, phát hiện và giảm thiểu sai lệch trong mô hình, gỡ lỗi và tuân thủ các quy định pháp lý, đặc biệt trong các ngành như tài chính, y tế, và tư pháp [28].
Các hạn chế khác:
Nondeterminism (Tính phi xác định): Cùng một câu lệnh có thể tạo ra các kết quả khác nhau mỗi lần chạy [8].
Chi phí: Việc đào tạo và vận hành các mô hình AI tạo sinh đòi hỏi tài nguyên tính toán và chi phí đáng kể [1].
Bảo mật và quyền riêng tư: Rủi ro về quyền riêng tư và bảo mật dữ liệu sẽ phát sinh nếu dữ liệu độc quyền của doanh nghiệp được sử dụng để tùy chỉnh các mô hình [1, 5, 25].

2.3. Các Yếu Tố Lựa Chọn Mô Hình AI Tạo Sinh

Quy trình lựa chọn mô hình AI tạo sinh phải được thực hiện một cách có hệ thống, bắt đầu từ việc xác định rõ vấn đề kinh doanh [24]. Các yếu tố chính cần xem xét bao gồm:
Loại mô hình: Lựa chọn mô hình phù hợp với loại hình nhiệm vụ (văn bản, hình ảnh, đa phương thức) [24].
Yêu cầu hiệu suất: Đánh giá độ chính xác, độ trễ và khả năng đáp ứng các yêu cầu cụ thể của ứng dụng [24].
Khả năng và Hạn chế: Cân nhắc kích thước mô hình, cửa sổ ngữ cảnh và khả năng xử lý các nhiệm vụ phức tạp [24].
Tuân thủ: Đảm bảo mô hình đáp ứng các tiêu chuẩn về đạo đức, bảo mật và pháp lý [2].
Cân bằng chi phí: Đánh giá chi phí đầu tư ban đầu và chi phí vận hành theo thời gian [24].

2.4. Đo Lường Giá Trị Kinh Doanh và Các Chỉ Số

Giá trị của một ứng dụng AI tạo sinh không được đo lường bằng hiệu suất kỹ thuật mà bằng các kết quả kinh doanh cuối cùng mà nó mang lại [3, 29]. Các chỉ số đo lường hiệu quả có thể được chia thành nhiều nhóm:
Hiệu suất Kinh doanh (Business Performance):
Tăng trưởng doanh thu [29].
Tối ưu hóa chi phí (ví dụ, tiết kiệm tới 30% chi phí vận hành nhờ tự động hóa) [29].
ROI (Lợi tức đầu tư) [29].
Hiệu quả (Efficiency):
Thời gian hoàn thành tác vụ [29].
Khối lượng công việc được xử lý [29].
Giảm tỷ lệ lỗi [29].
Trải nghiệm Khách hàng (Customer Experience):
Tốc độ phản hồi (ví dụ, chatbot giảm thời gian phản hồi từ vài giờ xuống vài giây) [29].
Tỷ lệ hài lòng của khách hàng (CSAT) [29].
Tỷ lệ giữ chân khách hàng (Retention Rate) [29].
Hiệu quả Marketing:
Tỷ lệ chuyển đổi (Conversion Rate) [29].
Giá trị trọn đời của khách hàng (CLV) [29].

Phần 3: Cơ Sở Hạ Tầng và Công Nghệ AWS (Task Statement 2.3)

3.1. Các Dịch Vụ và Tính Năng AWS để Phát Triển Ứng Dụng AI Tạo Sinh

AWS cung cấp một bộ dịch vụ toàn diện được thiết kế để hỗ trợ mọi giai đoạn của vòng đời AI tạo sinh, từ thử nghiệm đến triển khai quy mô lớn [1].
Amazon SageMaker JumpStart:
Chức năng: Một trung tâm máy học (ML Hub) giúp tăng tốc hành trình ML [30, 31]. SageMaker JumpStart cung cấp hàng trăm mô hình được tiền huấn luyện và các thuật toán tích hợp sẵn [30, 31].
Lợi ích: Người dùng có thể nhanh chóng khám phá, triển khai và tùy chỉnh các mô hình nền tảng bằng dữ liệu riêng của mình, tất cả đều được đảm bảo an toàn vì dữ liệu không rời khỏi đám mây riêng ảo (VPC) [30].
Amazon Bedrock:
Chức năng: Một dịch vụ được quản lý toàn phần, cung cấp quyền truy cập vào các mô hình nền tảng (FMs) hàng đầu từ các công ty AI hàng đầu thông qua một API duy nhất [15].
Lợi ích: Bedrock cung cấp sự lựa chọn đa dạng về mô hình, các công cụ tùy chỉnh linh hoạt, và các hàng rào bảo vệ như Bedrock Guardrails để giảm thiểu nội dung có hại và ảo giác [15].
PartyRock:
Chức năng: Một môi trường thử nghiệm "không cần mã" (no-code playground) được cung cấp bởi Amazon Bedrock [11, 32]. Nền tảng này được thiết kế để người dùng, đặc biệt là những người không có kinh nghiệm lập trình, có thể học prompt engineering và xây dựng các ứng dụng AI tạo sinh một cách nhanh chóng và thú vị [12].
Lợi ích: Rào cản gia nhập thấp, dễ dàng thử nghiệm và chia sẻ ứng dụng [12, 32].
Amazon Q:
Chức năng: Một trợ lý AI được thiết kế đặc biệt cho doanh nghiệp [33]. Amazon Q kết nối với dữ liệu nội bộ của công ty (tài liệu, wiki, cơ sở dữ liệu) để trả lời câu hỏi và tự động hóa các quy trình làm việc [34, 35].
Lợi ích: Tăng năng suất cho nhân viên bằng cách cung cấp thông tin thống nhất, chính xác và có ngữ cảnh, đồng thời đảm bảo tuân thủ các chính sách bảo mật và quyền truy cập của doanh nghiệp [34].
